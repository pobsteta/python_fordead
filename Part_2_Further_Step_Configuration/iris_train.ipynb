{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 2: Deploy a simple ML model - Further step configuration"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Import libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import craft_ai_sdk\n",
                "import dotenv\n",
                "import os\n",
                "import pandas as pd\n",
                "from sklearn import datasets"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load environnement variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dotenv.load_dotenv()\n",
                "\n",
                "SDK_TOKEN = os.environ[\"CRAFT_AI_ACCESS_TOKEN\"]\n",
                "ENVIRONMENT_URL = os.environ[\"CRAFT_AI_ENVIRONMENT_URL\"]"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## SDK instantiation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sdk = craft_ai_sdk.CraftAiSdk(sdk_token=SDK_TOKEN, environment_url=ENVIRONMENT_URL)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Clean Previous part"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can start by cleaning the objects we created in the hello world use case.\n",
                "\n",
                "To do so we can simply use `delete_pipeline` and `delete_step` functions of the sdk. \n",
                "\n",
                "/!\\ The order in which you call these functions is important since you can't delete a step that is used in the in a pipeline.\n",
                "\n",
                "<u>Tips</u> : you can also use directly the `delete_step` function with the argument `force_dependents_deletion` passed to `True`. It will delete everything linked to the step as well."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sdk.delete_pipeline(pipeline_name=\"part-1-hello-world\")\n",
                "sdk.delete_step(step_name=\"part-1-hello-world\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Upload dataset to Data Store"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This use case uses the famous Iris dataset.\n",
                "\n",
                "With the Craft.AI platform, your environment comes with computational resources and file storage. That's what we call the **data store**.\n",
                "\n",
                "You can upload and download files and organize them using the SDK.\n",
                "\n",
                "We will start by uploading this dataset to the data store using the `upload_data_store_object` function of the sdk. \n",
                "\n",
                "You have to pass two arguments:\n",
                "- `filepath_or_buffer` : path of the file to be uploaded or a file-like object\n",
                "- `object_path_in_datastore`: path to save the file to\n",
                "\n",
                "You can find further information in the SDK documentation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "iris = datasets.load_iris(as_frame=True)\n",
                "iris_df = pd.concat([iris.data, iris.target], axis=1)\n",
                "iris_df.to_parquet(\"iris.parquet\")\n",
                "\n",
                "sdk.upload_data_store_object(\n",
                "    filepath_or_buffer=\"iris.parquet\",\n",
                "    object_path_in_datastore=\"get_started/dataset/iris.parquet\",\n",
                ")\n",
                "\n",
                "os.remove(\"iris.parquet\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also check all the objects contained in the datastore using the `list_data_store_objects` function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sdk.list_data_store_objects()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And get information about a specific item with the `get_data_store_object_information` function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sdk.get_data_store_object_information(\"get_started/dataset/iris.parquet\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step creation with the SDK"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create a step"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, it's time to create the **step** embedding our code. \n",
                "\n",
                "We will do exactly what we have done previously in the *Hello_world* section, but this time we will use more advanced options.\n",
                "\n",
                "The argument `container_config` can contain many things to parametrize our step. Here we will focus on two specific parameters:\n",
                "- `included_folders`: sometimes you may not need tp include all the files of your preject repository in your step. You can then specify the files and folder(s) to be included to prevent the step from accessing all code available in the repository. Here we only want to include the `src` folder.\n",
                "- `requirements_path`: in order for our `requirements.txt` file to be taken into account and therefore to onboard all necessary librairies in the step, we add the path of this file in the `container_config`.\n",
                "\n",
                "You can find further information and configuration settings in the SDK documentation.\n",
                "\n",
                "The `included_folders` and `requirements_path` can also be **specified by default** directly in your project, on the platform (in the Settings of your project). If you specify those arguments in your step creation, it will take it first into account before checking the values set at the project level.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sdk.create_step(\n",
                "    step_name=\"part-2-iristrain\",\n",
                "    function_path=\"src/part-2-irisModel.py\",\n",
                "    function_name=\"TrainIris\",\n",
                "    description=\"This function creates a classifier model for iris\",\n",
                "    container_config={\n",
                "        \"requirements_path\": \"requirements.txt\",\n",
                "        \"included_folders\": [\"/src\"],\n",
                "    },\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create a pipeline"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create a pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sdk.create_pipeline(\n",
                "    pipeline_name=\"part-2-iristrain\",\n",
                "    step_name=\"part-2-iristrain\",\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run your Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sdk.run_pipeline(pipeline_name=\"part-2-iristrain\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Check model creation"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can check the creation of the model by investigating the data store.\n",
                "\n",
                "Using the previously introduced `get_data_store_object_information`, we can easily verify that the model has been created and well uploaded."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sdk.get_data_store_object_information(\"get_started/models/iris_knn_model.joblib\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally, to clean the datastore, we use the `delete_data_store_object` function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sdk.delete_data_store_object(\"get_started/models/iris_knn_model.joblib\")\n",
                "sdk.delete_data_store_object(\"get_started/dataset/iris.parquet\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.12 (default, Dec  1 2021, 18:28:47) \n[GCC 9.3.0]"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "232d0a11f8df5ff3a2ba2b13b61b4e3f653bd588275dad9272f8bdcbc6001c87"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
